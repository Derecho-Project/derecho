[DERECHO]
# leader ip - the leader's ip address
leader_ip = 127.0.0.1
# leader gms port - the leader's gms port
leader_gms_port = 23580
# leader external port - the leader's external port
leader_external_port = 32645
# my local id - each node should have a different id
local_id = 0
# my local ip address
local_ip = 127.0.0.1
# derecho gms port
gms_port = 23580
# derecho rpc port
rpc_port = 28366
# sst tcp port
sst_port = 37683
# rdmc tcp port
rdmc_port = 31675
# externel tcp port listening to external clients
external_port = 32645
# this is the frequency of the failure detector thread for MulticastGroup and P2PConnectionManager.
# It is best to leave this to 1 ms for RDMA. If it is too high,
# you run the risk of overflowing the queue of outstanding sends.
heartbeat_ms = 1
# sst poll completion queue timeout in millisecond
sst_poll_cq_timeout_ms = 100
# disable partitioning safety
# By disabling this feature, the derecho is allowed to run when active
# members cannot form a majority. Please be aware of the 'split-brain'
# syndrome:https://en.wikipedia.org/wiki/Split-brain and make sure your
# application is fine with it. 
# To help the user play with derecho at beginning, we disabled the
# partitioning safety. We suggest to set it to false for serious deployment
disable_partitioning_safety = true

# maximum payload size for P2P requests
max_p2p_request_payload_size = 10240
# maximum payload size for P2P replies
max_p2p_reply_payload_size = 10240
# window size for P2P requests and replies
p2p_window_size = 16

# Subgroup configurations
# - The default subgroup settings
[SUBGROUP/DEFAULT]
# maximum payload size
# Any message with size large than this has to be broken
# down to multiple messages.
# Large message consumes memory space because the memory buffers
# have to be pre-allocated.
max_payload_size = 10240
# maximum reply payload size
# This is for replies generated by ordered sends in the subgroup
max_reply_payload_size = 10240
# maximum smc (SST's small message multicast) payload size
# If the message size is smaller or equal to this size,
# it will be sent using SST multicast, otherwise it will
# try RDMC if the message size is smaller than max_payload_size.
max_smc_payload_size = 10240
# block size depends on your max_payload_size.
# It is only relevant if you are ever going to send a message using RDMC.
# In that case, it should be set to the same value as the max_payload_size,
# if the max_payload_size is around 1 MB. For very large messages, the block # size should be a few MBs (1 is fine).
block_size = 1048576
# message window size
# the length of the message pipeline
window_size = 16
# the send algorithm for RDMC. Other options are
# chain_send, sequential_send, tree_send
rdmc_send_algorithm = binomial_send
# - SAMPLE for large message settings
[SUBGROUP/LARGE]
max_payload_size = 102400
max_reply_payload_size = 102400
max_smc_payload_size = 10240
block_size = 10240
window_size = 3
rdmc_send_algorithm = binomial_send
# - SAMPLE for small message settings
[SUBGROUP/SMALL]
max_payload_size = 100
max_reply_payload_size = 100
max_smc_payload_size = 100
# TODO: avoid creat rdmc group if max_payload_size > max_smc_payload_size
block_size = 1024
window_size = 50
rdmc_send_algorithm = binomial_send

# RDMA section contains configurations of the following
# - which RDMA device to use
# - device configurations
[RDMA]
# 1. provider = bgq|gni|mlx|netdir|psm|psm2|rxd|rxm|shm|sockets|udp|usnic|verbs
# possible options(only 'sockets' and 'verbs' providers are tested so far):
# bgq     - The Blue Gene/Q Fabric Provider
# gni     - The GNI Fabric Provider (Cray XC (TM) systems)
# mlx     - The MLX Fabric Provider (UCX library)
# netdir  - The Network Direct Fabric Provider (Microsoft Network Direct SPI)
# psm     - The PSM Fabric Provider
# psm2    - The PSM2 Fabric Provider
# rxd     - The RxD (RDM over DGRAM) Utility Provider
# rxm     - The RxM (RDM over MSG) Utility Provider
# shm     - The SHM Fabric Provider
# sockets - The Sockets Fabric Provider (TCP)
# udp     - The UDP Fabric Provider
# usnic   - The usNIC Fabric Provider (Cisco VIC)
# verbs   - The Verbs Fabric Provider
provider = sockets

# 2. domain
# For sockets provider, domain is the NIC name (ifconfig | grep -v -e "^ ")
# For verbs provider, domain is the device name (ibv_devices)
domain = eth0

# 3. tx_depth 
# tx_depth applies to hints->tx_attr->size, where hint is a struct fi_info object.
# see https://ofiwg.github.io/libfabric/master/man/fi_getinfo.3.html
tx_depth = 256

# 4. rx_depth:
# rx_depth applies to hints->rx_attr->size, where hint is a struct fi_info object.
# see https://ofiwg.github.io/libfabric/master/man/fi_getinfo.3.html
rx_depth = 256

# Persistent configurations
[PERS]
# persistent directory for file system-based logfile.
file_path = .plog
ramdisk_path = /dev/shm/volatile_t
# Reset persistent data
# CAUTION: "reset = true" removes existing persisted data!!!
reset = false
# Max number of the log entries in each persistent<T>, default to 1048576
max_log_entry = 1048576
# Max data size in bytes for each persistent<T>, default to 512GB
max_data_size = 549755813888

# Logger configurations
[LOGGER]
# default log name
default_log_name = derecho_debug
# default log level
# Available options:
# trace,debug,info,warn,error,critical,off
default_log_level = info
